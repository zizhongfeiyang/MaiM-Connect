# MaiM v62_lianwang è”ç½‘å·¥å…·ç‰ˆæœ¬è¯´æ˜

## æ ¸å¿ƒåŠŸèƒ½

MaiM v62_lianwang æ˜¯ä¸€æ¬¾å¼ºå¤§çš„è”ç½‘å·¥å…·ç‰ˆæœ¬ï¼Œä¸»è¦ç‰¹ç‚¹æ˜¯å¢å¼ºäº†è”ç½‘èƒ½åŠ›å’ŒçŸ¥è¯†è·å–ç³»ç»Ÿï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿå®æ—¶è·å–ç½‘ç»œä¿¡æ¯å¹¶åº”ç”¨åˆ°å¯¹è¯ä¸­ã€‚

## ğŸ” è”ç½‘å·¥å…·ç³»ç»Ÿ

### ç½‘ç»œæœç´¢æ ¸å¿ƒåŠŸèƒ½
- **åŸºäº SearXNG çš„æœç´¢å¼•æ“é›†æˆ**ï¼šæ”¯æŒé…ç½®å¤šä¸ªæœç´¢å¼•æ“ï¼Œèšåˆç»“æœæé«˜æœç´¢è´¨é‡
- **æ™ºèƒ½è§¦å‘æœºåˆ¶**ï¼š`WebSearchTool` ç±»å®ç°äº†åŸºäºä¸Šä¸‹æ–‡çš„æœç´¢è§¦å‘åˆ¤æ–­ï¼Œé¿å…è¿‡åº¦æœç´¢
- **å†·å´æ—¶é—´æ§åˆ¶**ï¼šé€šè¿‡ `_check_cooldown()` æ–¹æ³•å®ç°æœç´¢é¢‘ç‡é™åˆ¶ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡ `SEARCH_COOLDOWN_SECONDS` é…ç½®
- **ç»“æœç¼“å­˜ç³»ç»Ÿ**ï¼šå®ç° 5 åˆ†é’Ÿå†…ç›¸åŒæŸ¥è¯¢çš„ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘é‡å¤è¯·æ±‚ï¼Œæé«˜å“åº”é€Ÿåº¦

### å¼€å‘è€…æ¥å£
```python
# åŸºæœ¬ä½¿ç”¨æ–¹æ³•
from src.do_tool.tool_can_use import get_tool_instance

web_search_tool = get_tool_instance("web_search")
result = await web_search_tool.execute({
    "query": "æœç´¢å†…å®¹", 
    "num_results": 5,
    "time_range": "week"  # æ”¯æŒ day, week, month, year
})
```

## ğŸ§  çŸ¥è¯†åº“é›†æˆ

### çŸ¥è¯†å­˜å‚¨ä¸æ£€ç´¢ç³»ç»Ÿ
- **æ–°å¢ `store_knowledge` å·¥å…·**ï¼šå°†æœç´¢ç»“æœè‡ªåŠ¨å­˜å…¥çŸ¥è¯†åº“ï¼Œæ”¯æŒè®¾ç½®é‡è¦æ€§å’Œç”Ÿå­˜æ—¶é—´
- **çŸ¥è¯†å»é‡ä¸æ›´æ–°æœºåˆ¶**ï¼šåŸºäºç›¸ä¼¼åº¦æ£€æµ‹ï¼Œé¿å…å­˜å‚¨é‡å¤å†…å®¹ï¼Œæ”¯æŒè¦†ç›–æ—§ä¿¡æ¯
- **è‡ªåŠ¨æ ‡ç­¾æå–**ï¼šå¯¹çŸ¥è¯†å†…å®¹è¿›è¡Œåˆ†æå¹¶ç”Ÿæˆæ ‡ç­¾ï¼Œä¾¿äºæ£€ç´¢å’Œå…³è”

### å¼€å‘è€…æ¥å£
```python
# çŸ¥è¯†å­˜å‚¨ç¤ºä¾‹
store_knowledge_tool = get_tool_instance("store_knowledge")
await store_knowledge_tool.execute({
    "query": "æœç´¢å…³é”®è¯",
    "content": "è¦å­˜å‚¨çš„çŸ¥è¯†å†…å®¹",
    "source": "web_search",
    "tags": ["æŠ€æœ¯", "æ–°é—»"],  # å¯é€‰
    "importance": 4,  # é‡è¦æ€§è¯„åˆ†(1-5)
    "ttl": 604800  # ç”Ÿå­˜æ—¶é—´(ç§’)ï¼Œé»˜è®¤7å¤©
})

# çŸ¥è¯†æ£€ç´¢ç¤ºä¾‹
get_knowledge_tool = get_tool_instance("get_knowledge")
knowledge = await get_knowledge_tool.execute({
    "query": "æŸ¥è¯¢å…³é”®è¯",
    "threshold": 0.7  # ç›¸ä¼¼åº¦é˜ˆå€¼
})
```

## ğŸ› ï¸ å·¥å…·ç³»ç»Ÿæ¡†æ¶

### æ–°å¢å·¥å…·ç±»
- **æ ¸å¿ƒæœç´¢å·¥å…·**ï¼š`WebSearchTool`ã€`SearchEngineTool`
- **çŸ¥è¯†ç®¡ç†å·¥å…·**ï¼š`StoreKnowledgeTool`ã€`GetKnowledgeTool`
- **è¾…åŠ©å·¥å…·**ï¼š`CompressContextTool`ï¼ˆä¸Šä¸‹æ–‡å‹ç¼©ï¼‰ã€`GetCurrentTaskTool`ï¼ˆæ—¥ç¨‹è·å–ï¼‰

### å·¥å…·æ³¨å†Œä¸è°ƒç”¨æœºåˆ¶
- **è‡ªåŠ¨æ³¨å†Œç³»ç»Ÿ**ï¼šå·¥å…·ç±»åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ³¨å†Œåˆ°å·¥å…·åº“
- **ç»Ÿä¸€è°ƒç”¨æ¥å£**ï¼šæ‰€æœ‰å·¥å…·é€šè¿‡ `execute()` æ–¹æ³•è°ƒç”¨ï¼Œæ”¯æŒå¼‚æ­¥æ“ä½œ
- **å¿ƒæµç³»ç»Ÿé›†æˆ**ï¼šå…è®¸å¿ƒæµç³»ç»Ÿæ ¹æ®éœ€è¦è‡ªåŠ¨è°ƒç”¨åˆé€‚çš„å·¥å…·

## ğŸ“ ç¯å¢ƒé…ç½®å‚æ•°

ä¸»è¦ç¯å¢ƒé…ç½®ï¼š

```
# æœç´¢å¼•æ“é…ç½®
SEARXNG_URL=http://localhost:32768  # SearXNGå®ä¾‹URL
SEARXNG_AUTH_TOKEN=your_token_here  # å¯é€‰è®¤è¯ä»¤ç‰Œ

# æœç´¢æ§åˆ¶
SEARCH_COOLDOWN_SECONDS=600  # æœç´¢å†·å´æ—¶é—´(ç§’)
SEARCH_RESULT_LIMIT=10  # é»˜è®¤æœç´¢ç»“æœæ•°é‡é™åˆ¶

# çŸ¥è¯†åº“é…ç½®
KNOWLEDGE_TTL_DEFAULT=604800  # é»˜è®¤çŸ¥è¯†ç”Ÿå­˜æ—¶é—´(ç§’)
KNOWLEDGE_SIMILARITY_THRESHOLD=0.75  # çŸ¥è¯†å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼
```

## ğŸ”§ éƒ¨ç½²æŒ‡å—

è”ç½‘å·¥å…·çš„éƒ¨ç½²éœ€è¦å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

1. **SearXNG æœç´¢å¼•æ“è®¾ç½®**ï¼š
   ```bash
   # ä½¿ç”¨Dockerå®‰è£…SearXNG
   docker pull searxng/searxng
   docker run -d -p 32768:8080 --name searxng searxng/searxng
   ```

2. **ç¯å¢ƒå˜é‡é…ç½®**ï¼šåˆ›å»ºæˆ–ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ·»åŠ å¿…è¦çš„æœç´¢å¼•æ“é…ç½®

3. **ä¾èµ–å®‰è£…**ï¼š
   ```bash
   pip install aiohttp beautifulsoup4 urllib3
   ```

## ğŸ“– å¼€å‘è€…ç¤ºä¾‹

### å®Œæ•´å·¥å…·é“¾ä½¿ç”¨ç¤ºä¾‹

```python
import asyncio
from src.do_tool.tool_can_use import get_tool_instance

async def search_and_store_knowledge(query):
    # 1. æ‰§è¡Œç½‘ç»œæœç´¢
    web_search = get_tool_instance("web_search")
    search_result = await web_search.execute({"query": query, "num_results": 5})
    
    if "content" not in search_result or "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ" in search_result["content"]:
        return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
    
    # 2. å­˜å‚¨åˆ°çŸ¥è¯†åº“
    store_knowledge = get_tool_instance("store_knowledge")
    await store_knowledge.execute({
        "query": query,
        "content": search_result["content"],
        "source": "web_search",
        "importance": 3
    })
    
    # 3. å‹ç¼©ä¸Šä¸‹æ–‡å¹¶è¿”å›ç»“æœ
    compress = get_tool_instance("compress_context")
    compressed = await compress.execute({
        "text": search_result["content"],
        "max_length": 500
    })
    
    return compressed["content"]

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    result = asyncio.run(search_and_store_knowledge("æœ€æ–°äººå·¥æ™ºèƒ½æŠ€æœ¯"))
    print(result)
```

---

*MaiM v62_lianwang è”ç½‘å·¥å…·ç³»ç»Ÿä¸ºæœºå™¨äººå¢åŠ äº†è·å–å®æ—¶ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä½¿å…¶æ›´åŠ æ™ºèƒ½å’Œå®ç”¨ã€‚å¼€å‘è€…å¯ä»¥è½»æ¾æ‰©å±•å’Œå®šåˆ¶è¿™ä¸€ç³»ç»Ÿï¼Œæ»¡è¶³å„ç§åº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚* 